import os
import random

import albumentations as A  # noqa: N812
import cv2
import grain
import jax.numpy as jnp
import matplotlib.pyplot as plt
import numpy as np
import optax
import orbax.checkpoint as ocp
import torch
from flax import nnx
from tqdm import tqdm

from models.resnet import resnet50

# Configuration
params = {
    "num_epochs": 300,
    "batch_size": 64,
    "target_size": 224,
    "learning_rate": 5e-4,
    "weight_decay": 1e-4,
    "seed": 42,
    "num_classes": 16,
    "train_data_path": "./MpoxData/train",
    "val_data_path": "./MpoxData/validation",
    "checkpoint_dir": "/Users/billy/Documents/DLStudy/JaxVision/checkpoints",
}


def set_seed(seed):
    """Set random seeds for reproducibility"""
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)  # noqa: NPY002
    random.seed(seed)


def load_image(img_path):
    """Load image in RGB format"""
    img = cv2.imread(img_path)
    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)


def create_transforms(target_size, is_training=True) -> A.Compose:  # noqa: FBT002
    """
    ä¸ºçš®è‚¤ç—…å›¾åƒåˆ›å»ºæ•°æ®å¢å¼ºå˜æ¢ã€‚

    è€ƒè™‘äº†çš®è‚¤ç—…å›¾åƒçš„ç‰¹å®šéœ€æ±‚ï¼Œæ—¨åœ¨ä¿ç•™ç—…ç¶ç‰¹å¾å¹¶å¢åŠ æ•°æ®å¤šæ ·æ€§ã€‚
    """  # noqa: RUF002
    transforms_list = [
        # å›ºå®šå›¾åƒå¤§å°ï¼Œç¡®ä¿æ‰€æœ‰è¾“å…¥å›¾åƒå°ºå¯¸ä¸€è‡´  # noqa: RUF003
        A.Resize(height=target_size, width=target_size, p=1.0),
    ]

    if is_training:
        transforms_list.extend(
            [
                # å‡ ä½•å˜æ¢ï¼šå¯¹äºçš®è‚¤ç—…å›¾åƒé€šå¸¸æ˜¯å®‰å…¨çš„ï¼Œå¯ä»¥å¢åŠ æ¨¡å‹çš„æ—‹è½¬å’Œç¿»è½¬ä¸å˜æ€§ã€‚  # noqa: RUF003
                # è§’åº¦é™åˆ¶å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼Œé¿å…è¿‡åº¦æ—‹è½¬å¯¼è‡´ç—…ç¶è¯†åˆ«å›°éš¾ã€‚  # noqa: RUF003
                A.HorizontalFlip(p=0.5),
                A.VerticalFlip(p=0.5),
                A.Rotate(
                    limit=30, p=0.5, border_mode=cv2.BORDER_REFLECT_101
                ),  # ä½¿ç”¨ cv2.BORDER_REFLECT_101 å¡«å……è¾¹ç¼˜
                # é¢œè‰²æŠ–åŠ¨ï¼šé€‚åº¦è°ƒæ•´å¯ä»¥æ¨¡æ‹Ÿä¸åŒå…‰ç…§æ¡ä»¶å’Œç›¸æœºè®¾ç½®ã€‚  # noqa: RUF003
                # å¯¹äºçš®è‚¤ç—…å›¾åƒï¼Œhueï¼ˆè‰²ç›¸ï¼‰çš„è°ƒæ•´éœ€è¦ç‰¹åˆ«å°å¿ƒï¼Œå› ä¸ºé¢œè‰²å˜åŒ–å¯èƒ½å½±å“ç—…ç¶çš„è¯†åˆ«ã€‚  # noqa: RUF003
                # å¯ä»¥è€ƒè™‘å‡å° hue çš„èŒƒå›´æˆ–å¯¹å…¶è¿›è¡Œæ›´ç²¾ç»†çš„æ§åˆ¶ã€‚
                A.ColorJitter(
                    brightness=0.2,
                    contrast=0.2,
                    saturation=0.2,
                    hue=0.05,  # å‡å° hue çš„å˜åŒ–èŒƒå›´
                    p=0.5,
                ),
                # é¢å¤–çš„å‡ ä½•å˜æ¢ï¼š  # noqa: RUF003
                # RandomResizedCrop: æ¨¡æ‹Ÿä¸åŒè§†è§’ä¸‹çš„ç—…ç¶ï¼Œä½†éœ€æ³¨æ„ä¸è¦è£æ‰å…³é”®ç—…ç¶åŒºåŸŸã€‚  # noqa: RUF003
                # å¯¹äºçš®è‚¤ç—…å›¾åƒï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨æ›´ä¿å®ˆçš„è£å‰ªå‚æ•°ï¼Œæˆ–è€…åªåœ¨ç¡®è®¤ç—…ç¶å æ®å›¾åƒå¤§éƒ¨åˆ†åŒºåŸŸæ—¶ä½¿ç”¨ã€‚  # noqa: RUF003
                A.RandomResizedCrop(
                    size=(target_size, target_size),
                    scale=(0.8, 1.0),
                    ratio=(0.75, 1.33),
                    p=0.3,
                ),
                # Affineå˜æ¢ï¼šå¯ä»¥æ¨¡æ‹Ÿè½»å¾®çš„é€è§†æˆ–ç•¸å˜ï¼Œæœ‰åŠ©äºæ¨¡å‹æ³›åŒ–ã€‚  # noqa: RUF003
                A.Affine(
                    shear=(-10, 10),
                    rotate=(-10, 10),
                    scale=(0.9, 1.1),
                    p=0.3,
                    mode=cv2.BORDER_REFLECT_101,
                ),
                # æ¨¡ç³Šï¼šå¯ä»¥æ¨¡æ‹Ÿå›¾åƒå¤±ç„¦æˆ–ä½è´¨é‡å›¾åƒï¼Œå¢åŠ æ¨¡å‹çš„é²æ£’æ€§ã€‚  # noqa: RUF003
                # å¯¹äºçš®è‚¤ç—…å›¾åƒï¼Œè¿‡åº¦æ¨¡ç³Šå¯èƒ½ä½¿ç»†èŠ‚æ¶ˆå¤±ï¼Œæ‰€ä»¥éœ€è¦è°¨æ…ã€‚  # noqa: RUF003
                A.GaussianBlur(blur_limit=(3, 7), p=0.1),  # è½»å¾®é«˜æ–¯æ¨¡ç³Š
                A.MotionBlur(blur_limit=(3, 7), p=0.1),  # è½»å¾®è¿åŠ¨æ¨¡ç³Š
                # å™ªå£°ï¼šæ¨¡æ‹Ÿä¼ æ„Ÿå™¨å™ªå£°æˆ–å›¾åƒé‡‡é›†è¿‡ç¨‹ä¸­çš„éšæœºå¹²æ‰°ã€‚  # noqa: RUF003
                A.GaussNoise(var_limit=(10.0, 50.0), p=0.1),  # æ·»åŠ é«˜æ–¯å™ªå£°
                # å¼¹åŠ›å˜å½¢ (ElasticTransform)ï¼šå¯ä»¥ç”Ÿæˆæ–°çš„ç—…ç¶å½¢çŠ¶ï¼Œä½†è¦æ³¨æ„ä¸è¦è¿‡åº¦å˜å½¢ï¼Œä»¥å…ç”Ÿæˆéè‡ªç„¶çš„ç—…ç¶ã€‚  # noqa: RUF003
                # å¯¹äºçš®è‚¤ç—…å›¾åƒï¼Œéœ€è¦ä»”ç»†è°ƒæ•´å‚æ•°ï¼Œä»¥ç¡®ä¿å˜å½¢åçš„ç—…ç¶ä»ç„¶å…·æœ‰åŒ»å­¦åˆç†æ€§ã€‚  # noqa: RUF003
                A.ElasticTransform(
                    alpha=1,
                    sigma=50,
                    alpha_affine=50,
                    border_mode=cv2.BORDER_REFLECT_101,
                    p=0.1,
                ),
                # ç½‘æ ¼å¤±çœŸ (GridDistortion)ï¼šä¸å¼¹åŠ›å˜å½¢ç±»ä¼¼ï¼Œå¯ä»¥å¼•å…¥å±€éƒ¨å˜å½¢ã€‚  # noqa: RUF003
                A.GridDistortion(
                    num_steps=5,
                    distort_limit=0.3,
                    border_mode=cv2.BORDER_REFLECT_101,
                    p=0.1,
                ),
                # éšæœºæ“¦é™¤ (RandomErasing)ï¼šé®æŒ¡éƒ¨åˆ†åŒºåŸŸï¼Œä¿ƒä½¿æ¨¡å‹å­¦ä¹ å±€éƒ¨ç‰¹å¾è€Œä¸æ˜¯ä¾èµ–æ•´ä½“ç»“æ„ã€‚  # noqa: RUF003
                # å¯¹äºç—…ç¶è¾ƒå°çš„å›¾åƒï¼Œéœ€è¦è°¨æ…ä½¿ç”¨ï¼Œé¿å…æ“¦é™¤æ•´ä¸ªç—…ç¶ã€‚  # noqa: RUF003
                A.CoarseDropout(
                    max_holes=8,
                    max_height=int(target_size * 0.1),
                    max_width=int(target_size * 0.1),
                    min_holes=1,
                    min_height=int(target_size * 0.05),
                    min_width=int(target_size * 0.05),
                    p=0.1,
                ),
            ]
        )

    transforms_list.append(
        A.Normalize(
            mean=[0.485, 0.456, 0.406],  # ImageNet å‡å€¼
            std=[0.229, 0.224, 0.225],  # ImageNet æ ‡å‡†å·®
            max_pixel_value=255.0,
        )
    )

    return A.Compose(transforms_list)


class AlbumentationsTransform(grain.transforms.Map):
    def __init__(self, transforms):
        self.transforms = transforms

    def map(self, element: tuple[np.ndarray, int]) -> tuple[np.ndarray, int]:
        return (self.transforms(image=element[0])["image"], element[1])


class LoadImageMap(grain.transforms.Map):
    def map(self, element: tuple[str, int]) -> tuple[np.ndarray, int]:
        """Load image from path and return as numpy array with label"""
        img_path, label = element
        img = cv2.imread(img_path)
        if img is None:
            msg = f"Image at {img_path} could not be loaded."
            raise ValueError(msg)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        return img, label


class CustomImageFolderDataSource:
    def __init__(self, root_dir: str):
        self.root_dir = root_dir
        self.samples: list[tuple[str, int]] = []  # å­˜å‚¨ (image_path, class_idx)
        self.classes: list[str] = []  # å­˜å‚¨ç±»åˆ«åç§°

        # è¿™éƒ¨åˆ†é€»è¾‘ä¸ ImageFolder çš„å†…éƒ¨å®ç°ç±»ä¼¼ï¼Œç”¨äºéå†ç›®å½•å’Œæ˜ å°„ç±»åˆ«  # noqa: RUF003
        class_to_idx = {}
        idx_to_class = []

        if not os.path.isdir(root_dir):  # noqa: PTH112
            msg = f"Root directory not found: {root_dir}"
            raise FileNotFoundError(msg)

        # éå†æ ¹ç›®å½•ä¸‹çš„æ¯ä¸ªå­ç›®å½•ï¼ˆä»£è¡¨ä¸€ä¸ªç±»åˆ«ï¼‰  # noqa: RUF003
        for target_class_name in sorted(os.listdir(root_dir)):  # noqa: PTH208
            class_dir_path = os.path.join(root_dir, target_class_name)  # noqa: PTH118
            if not os.path.isdir(class_dir_path):  # noqa: PTH112
                continue  # è·³è¿‡éç›®å½•æ–‡ä»¶

            # ä¸ºç±»åˆ«åˆ†é…ä¸€ä¸ªç´¢å¼•
            if target_class_name not in class_to_idx:
                class_to_idx[target_class_name] = len(class_to_idx)
                idx_to_class.append(target_class_name)

            class_idx = class_to_idx[target_class_name]

            # éå†ç±»åˆ«ç›®å½•ä¸‹çš„æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
            for img_file_name in sorted(os.listdir(class_dir_path)):  # noqa: PTH208
                img_path = os.path.join(class_dir_path, img_file_name)  # noqa: PTH118
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ˜¯å›¾ç‰‡ï¼ˆè¿™é‡Œåªåšäº†ç®€å•çš„æ‰©å±•ååˆ¤æ–­ï¼Œå¯ä»¥æ›´å®Œå–„ï¼‰  # noqa: RUF003
                if os.path.isfile(img_path) and img_file_name.lower().endswith(  # noqa: PTH113
                    (".png", ".jpg", ".jpeg", ".gif", ".bmp")
                ):
                    self.samples.append((img_path, class_idx))

        self.classes = idx_to_class
        if not self.samples:
            msg = f"åœ¨ç›®å½• '{root_dir}' ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å›¾ç‰‡ã€‚è¯·æ£€æŸ¥ç›®å½•ç»“æ„å’Œæ–‡ä»¶æ‰©å±•åã€‚"
            raise RuntimeError(
                msg
            )

    def __len__(self) -> int:
        return len(self.samples)

    def __getitem__(self, index: int) -> tuple[str, int]:
        return self.samples[index]


def create_datasets(params):
    """Create training and validation datasets"""
    train_dataset = CustomImageFolderDataSource(params["train_data_path"])

    val_dataset = CustomImageFolderDataSource(params["val_data_path"])

    return train_dataset, val_dataset


def create_dataloaders(train_dataset, val_dataset, params):
    """Create data loaders"""
    train_loader = (
        grain.MapDataset.source(train_dataset)
        .shuffle(seed=params["seed"])
        .map(LoadImageMap())
        .map(
            AlbumentationsTransform(
                create_transforms(params["target_size"], is_training=True)
            )
        )
        .to_iter_dataset()
        .batch(
            batch_size=params["batch_size"],
            drop_remainder=True,
            batch_fn=lambda ts: (
                np.stack([t[0] for t in ts], axis=0),
                np.stack([t[1] for t in ts], axis=0),
            ),
        )
    )
    val_loader = (
        grain.MapDataset.source(val_dataset)
        .shuffle(seed=params["seed"])
        .map(LoadImageMap())
        .map(
            AlbumentationsTransform(
                create_transforms(params["target_size"], is_training=False)
            )
        )
        .to_iter_dataset()
        .batch(
            batch_size=params["batch_size"],
            drop_remainder=False,
            batch_fn=lambda ts: (
                np.stack([t[0] for t in ts], axis=0),
                np.stack([t[1] for t in ts], axis=0),
            ),
        )
    )

    return train_loader, val_loader


def create_model(seed, num_classes):
    """Create a new model"""
    return resnet50(rngs=nnx.Rngs(seed), num_classes=num_classes)


def save_model(model, path):
    """Save model state"""
    os.makedirs(os.path.dirname(path), exist_ok=True)  # noqa: PTH103, PTH120
    checkpointer = ocp.PyTreeCheckpointer()
    state = nnx.state(model)
    checkpointer.save(path, state)


def load_model(path, num_classes):
    """Load model from checkpoint"""
    model = nnx.eval_shape(lambda: create_model(0, num_classes))
    state = nnx.state(model)

    checkpointer = ocp.PyTreeCheckpointer()
    state = checkpointer.restore(path, item=state)

    nnx.update(model, state)
    return model


def loss_fn(model, batch):
    """Calculate loss and logits"""
    images, labels = batch
    logits = model(images)
    loss = optax.softmax_cross_entropy_with_integer_labels(
        logits=logits, labels=labels
    ).mean()
    return loss, logits


@nnx.jit
def train_step(model, optimizer, metrics, batch):
    """Single training step"""
    # Convert numpy arrays to jnp.array on GPU
    x, y_true = jnp.asarray(batch[0]), jnp.asarray(batch[1])
    grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)
    (loss, logits), grads = grad_fn(model, (x, y_true))
    metrics.update(loss=loss, logits=logits, labels=y_true)
    optimizer.update(grads)


@nnx.jit
def eval_step(model, metrics, batch):
    """Single evaluation step"""
    # convert numpy arrays to jnp.array on GPU
    x, y_true = jnp.asarray(batch[0]), jnp.asarray(batch[1])
    loss, logits = loss_fn(model, (x, y_true))
    metrics.update(loss=loss, logits=logits, labels=y_true)


def train_epoch(model, optimizer, metrics, train_loader, epoch_num):
    """Train for one epoch"""
    model.train()
    for batch in tqdm(train_loader, desc=f"Epoch {epoch_num + 1} Training"):
        train_step(model, optimizer, metrics, batch)

    result = metrics.compute()
    metrics.reset()

    print(f"âœ… Train Loss: {result['loss']:.4f}, Acc: {result['accuracy'] * 100:.6f}%")
    return result


def validate_epoch(model, metrics, val_loader, epoch_num):
    """Validate for one epoch"""
    model.eval()
    for batch in tqdm(val_loader, desc=f"Epoch {epoch_num + 1} Validation"):
        eval_step(model, metrics, batch)

    result = metrics.compute()
    metrics.reset()

    print(f"ğŸ“Š Val Loss: {result['loss']:.4f}, Acc: {result['accuracy'] * 100:.6f}%")
    return result


def update_metrics_history(metrics_history, train_result, val_result):
    """Update metrics history"""
    for k, v in train_result.items():
        metrics_history[f"train_{k}"].append(float(v))

    for k, v in val_result.items():
        metrics_history[f"val_{k}"].append(float(v))


def save_best_model_if_improved(model, val_result, best_acc, epoch_num, checkpoint_dir):
    """Save model if it's the best so far"""
    current_acc = float(val_result["accuracy"])

    if current_acc > best_acc:
        checkpoint_path = os.path.join(  # noqa: PTH118
            checkpoint_dir,
            f"best_model_Epoch_{epoch_num + 1}_Acc_{current_acc:.6f}",
            "state",
        )
        save_model(model, checkpoint_path)
        print(f"ğŸ‰ New best model saved with accuracy: {current_acc * 100:.6f}%")
        return current_acc

    return best_acc


def plot_training_metrics(metrics_history):
    """Plot training and validation metrics"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

    epochs = range(1, len(metrics_history["train_loss"]) + 1)

    # Plot loss
    ax1.plot(epochs, metrics_history["train_loss"], label="Train Loss", marker="o")
    ax1.plot(epochs, metrics_history["val_loss"], label="Val Loss", marker="s")
    ax1.set_title("Training and Validation Loss")
    ax1.set_xlabel("Epoch")
    ax1.set_ylabel("Loss")
    ax1.legend()
    ax1.grid(True, alpha=0.3)  # noqa: FBT003

    # Plot accuracy
    ax2.plot(
        epochs, metrics_history["train_accuracy"], label="Train Accuracy", marker="o"
    )
    ax2.plot(epochs, metrics_history["val_accuracy"], label="Val Accuracy", marker="s")
    ax2.set_title("Training and Validation Accuracy")
    ax2.set_xlabel("Epoch")
    ax2.set_ylabel("Accuracy")
    ax2.legend()
    ax2.grid(True, alpha=0.3)  # noqa: FBT003

    plt.tight_layout()
    plt.show()


def print_dataset_info(train_dataset, val_dataset):
    """Print dataset information"""
    print("ğŸ“Š Dataset Info:")
    print(f"  Train samples: {len(train_dataset)}")
    print(f"  Validation samples: {len(val_dataset)}")
    print(f"  Classes: {train_dataset.classes}")
    print(f"  Number of classes: {len(train_dataset.classes)}")


def main():
    """Main training function"""
    set_seed(params["seed"])

    print("ğŸš€ Starting training with ResNet18...")
    print(f"ğŸ“‹ Configuration: {params}")

    # Create datasets and dataloaders
    print("\nğŸ“‚ Loading datasets...")
    train_dataset, val_dataset = create_datasets(params)
    train_loader, val_loader = create_dataloaders(train_dataset, val_dataset, params)

    print_dataset_info(train_dataset, val_dataset)

    # Create model and optimizer
    print("\nğŸ—ï¸ Creating model and optimizer...")
    model = create_model(params["seed"], params["num_classes"])

    optimizer = nnx.Optimizer(
        model,
        optax.adamw(
            learning_rate=params["learning_rate"],
            weight_decay=params["weight_decay"],
        ),
    )

    metrics = nnx.MultiMetric(
        accuracy=nnx.metrics.Accuracy(),
        loss=nnx.metrics.Average("loss"),
    )

    # Initialize tracking variables
    metrics_history = {
        "train_loss": [],
        "train_accuracy": [],
        "val_loss": [],
        "val_accuracy": [],
    }
    best_acc = -1.0

    # Training loop
    print(f"\nğŸƒ Starting training for {params['num_epochs']} epochs...")

    for epoch in range(params["num_epochs"]):
        print(f"\n{'=' * 60}")
        print(f"Epoch {epoch + 1}/{params['num_epochs']}")
        print(f"{'=' * 60}")

        # Train and validate
        train_result = train_epoch(model, optimizer, metrics, train_loader, epoch)
        val_result = validate_epoch(model, metrics, val_loader, epoch)

        # Update metrics history
        update_metrics_history(metrics_history, train_result, val_result)

        # Save best model
        best_acc = save_best_model_if_improved(
            model, val_result, best_acc, epoch, params["checkpoint_dir"]
        )

    print("\nğŸ¯ Training completed!")
    print(f"ğŸ† Best validation accuracy: {best_acc * 100:.6f}%")

    # Plot results
    print("\nğŸ“ˆ Plotting training metrics...")
    plot_training_metrics(metrics_history)


if __name__ == "__main__":
    main()
